
# MODELLING ILLUSTRAIONS USING GAN

Facial image generation has been extensively studied since the emergence of Generative Adversarial Networks (GANs). Our focus is on training DCGAN models specialized for animated facial images, aiming to automatically generate faces of animated characters based on input training data. This involves tasks like image importation, analysis, and manipulation to produce altered or analyzed outputs. Recent advancements in single image super-resolution have prioritized minimizing mean squared reconstruction error, yielding high signal-to-noise ratios but often lacking in high-frequency details and perceptual fidelity at higher resolutions. Our goal is to develop a model that, given input tags, outputs corresponding generated images using both generator and discriminator components of GANs, enhancing the quality of images from low-resolution inputs through competitive training.

